{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTH6Pb-MGRPV",
        "outputId": "b164c6c4-64f7-41fe-f134-7e17ef04a2e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import math\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "ZDWwPbcBHl-k"
      },
      "outputs": [],
      "source": [
        "file_path = \"arxiv_subset.json\"\n",
        "\n",
        "TOP_N = 100 # top n docs retrieved by BM25\n",
        "TOP_K = 50 # top k docs retrieved by SBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "qJtJGfuCGR_e"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "\n",
        "        if not isinstance(text, str):\n",
        "           return \"\"\n",
        "\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "        text = re.sub(r'[^a-zA-Z\\s.,;!?]', '', text) # Removes anything, but letters and some punc\n",
        "\n",
        "        text = re.sub(r'\\s+', ' ', text.lower().strip())\n",
        "\n",
        "        tokens = word_tokenize(text)\n",
        "\n",
        "        tokens = [lemmatizer.lemmatize(token) for token in tokens if len(token) > 1] #heavy on memory\n",
        "\n",
        "        return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "WIqci4ekGdUe"
      },
      "outputs": [],
      "source": [
        "def check_doc_content(doc):\n",
        "\n",
        "        content = [\"id\", \"title\", \"abstract\", \"authors\", \"update_date\"]\n",
        "\n",
        "        for key in content:\n",
        "\n",
        "            if not doc.get(key, \"\").strip(): # Empty or Blank spaces\n",
        "\n",
        "                return True\n",
        "\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "zMtAfwksGojZ"
      },
      "outputs": [],
      "source": [
        "def load_text_data(file_path, num_papers = None):\n",
        "\n",
        "        docs = []\n",
        "\n",
        "        with open(file_path, \"r\", encoding = \"utf-8\") as file:\n",
        "\n",
        "            for i, line in enumerate(file):\n",
        "\n",
        "                paper = json.loads(line)  # Convert JSON string to dictionary\n",
        "\n",
        "                if check_doc_content(paper):\n",
        "                    continue\n",
        "\n",
        "                doc = dict(\n",
        "                    id  =  paper[\"id\"],\n",
        "                    title =  paper[\"title\"],\n",
        "                    abstract = paper[\"abstract\"],\n",
        "                    authors = paper[\"authors\"],\n",
        "                    publication_date =  paper[\"update_date\"]\n",
        "                )\n",
        "\n",
        "                docs.append(doc)\n",
        "\n",
        "                if num_papers is not None and i == num_papers - 1:\n",
        "                    break\n",
        "\n",
        "        return docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "j9th7uamGrtA"
      },
      "outputs": [],
      "source": [
        "def process_text(documents):\n",
        "\n",
        "        text_data = []\n",
        "\n",
        "        for doc in documents:\n",
        "\n",
        "            text = doc[\"title\"] + \" \" + doc[\"abstract\"]\n",
        "\n",
        "            text = clean_text(text)\n",
        "\n",
        "            text_data.append(text)\n",
        "\n",
        "        vectorizer = CountVectorizer(stop_words = 'english')\n",
        "\n",
        "        documents_vectorized = vectorizer.fit_transform(text_data) # Term count across docs\n",
        "        vocabulary = vectorizer.get_feature_names_out() # Creating the term vocabulary\n",
        "\n",
        "        # Matrix with doc ids as rows and vocabulary terms as cols\n",
        "        dataframe = pd.DataFrame(documents_vectorized.toarray(), columns = vocabulary)\n",
        "\n",
        "        return  text_data, vocabulary, dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "tKkH9fiqGuOB"
      },
      "outputs": [],
      "source": [
        "def process_query(query, vocabulary):\n",
        "\n",
        "        query = clean_text(query)\n",
        "\n",
        "        vectorizer = CountVectorizer(stop_words = 'english', vocabulary = vocabulary)\n",
        "\n",
        "        q_terms = vectorizer.build_analyzer()(query)\n",
        "\n",
        "        filtered_tokens = [term for term in q_terms if term in vocabulary]\n",
        "\n",
        "        return filtered_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "mU6RyklDReTK"
      },
      "outputs": [],
      "source": [
        "def highlight_terms(text, query_terms):\n",
        "    \"\"\"Highlight query terms in text using HTML bold tags\"\"\"\n",
        "    tokens = word_tokenize(text)\n",
        "    highlighted = []\n",
        "\n",
        "    for token in tokens:\n",
        "\n",
        "        cleaned_token = clean_text(token)\n",
        "\n",
        "        if cleaned_token in query_terms:\n",
        "\n",
        "            highlighted.append(f\"<b>{token}</b>\")\n",
        "\n",
        "        else:\n",
        "\n",
        "            highlighted.append(token)\n",
        "\n",
        "    return ' '.join(highlighted)\n",
        "\n",
        "\n",
        "def display_results(doc_indices, scores, df, query_terms):\n",
        "    \"\"\"Display results in a formatted table\"\"\"\n",
        "    results = []\n",
        "\n",
        "    for idx, score in zip(doc_indices, scores):\n",
        "\n",
        "        paper = df.iloc[idx]\n",
        "        highlighted_title = highlight_terms(paper['title'], query_terms)\n",
        "        highlighted_abstract = highlight_terms(paper['abstract'], query_terms)\n",
        "\n",
        "        results.append({\n",
        "            'DocID': paper['id'],\n",
        "            'Title': highlighted_title,\n",
        "            'Authors': ', '.join(paper['authors']),\n",
        "            'Year': paper['publication_date'][:4],  # Extract year from date\n",
        "            'Score': f'{score:.4f}',\n",
        "            'Abstract': highlighted_abstract[:150] + '...'\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "C1eqXJVWG3Oq"
      },
      "outputs": [],
      "source": [
        "class BM25_Model:\n",
        "\n",
        "    def __init__(self, documents, text_data, vocabulary, dataframe):\n",
        "\n",
        "        self.documents = documents\n",
        "        self.text_data = text_data\n",
        "        self.vocabulary = vocabulary\n",
        "        self.dataframe = dataframe\n",
        "\n",
        "        self.k_1 =  1.2\n",
        "        self.b = 0.75\n",
        "\n",
        "        self.bm25_dataframe = self.calculate_scores()\n",
        "\n",
        "# Checked!\n",
        "    def calculate_scores(self):\n",
        "\n",
        "        tfs = self.dataframe.div(self.dataframe.sum(axis = 1), axis = 0)\n",
        "        dfs = (self.dataframe > 0).sum(axis = 0).to_numpy()\n",
        "        idfs = np.log10(len(self.text_data) / dfs)\n",
        "        #tf_idf = tfs * idfs\n",
        "\n",
        "        dls = self.dataframe.sum(axis = 1).to_numpy()  # array of size N where N is the number of documents\n",
        "        avgdl = np.mean(dls)  # single value\n",
        "\n",
        "        numerator = np.array((self.k_1 + 1) * tfs)\n",
        "        denominator = np.array(self.k_1 *((1 - self.b) + self.b * (dls / avgdl))).reshape(-1, 1) + np.array(tfs)\n",
        "\n",
        "        BM25_tf = numerator / denominator\n",
        "\n",
        "        BM25_score = idfs * BM25_tf\n",
        "\n",
        "        bm25_dataframe = pd.DataFrame(BM25_score, columns = self.vocabulary)\n",
        "\n",
        "        return bm25_dataframe\n",
        "\n",
        "# Checked!\n",
        "    def rank_documents(self, q_terms, top_n):\n",
        "\n",
        "        q_terms_only_df = self.bm25_dataframe[q_terms]\n",
        "\n",
        "        score_q_d = q_terms_only_df.sum(axis = 1)\n",
        "\n",
        "        ranked_docs = sorted(zip(enumerate(self.text_data), score_q_d.values),\n",
        "                     key = lambda tup:tup[1],\n",
        "                     reverse = True)\n",
        "\n",
        "        if top_n >  len(ranked_docs):\n",
        "\n",
        "            top_n = len(ranked_docs)\n",
        "\n",
        "        ranked_docs = [doc for doc in ranked_docs if doc[1] > 0]\n",
        "\n",
        "        ranked_docs = ranked_docs[:top_n]\n",
        "\n",
        "        '''for doc in ranked_docs:\n",
        "\n",
        "          print(f'\\nScore: {doc[1]:.4f}, Document {doc[0][0]}: \"{doc[0][1]}\"')'''\n",
        "\n",
        "        return ranked_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "_DJkAOrCG33t"
      },
      "outputs": [],
      "source": [
        "class SBERT_Model:\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        self.sbert_model = SentenceTransformer('all-mpnet-base-v2')\n",
        "\n",
        "\n",
        "    def rank_documents(self, ranked_docs, query, top_k):\n",
        "\n",
        "        if top_k > len(ranked_docs):\n",
        "\n",
        "            top_k = len(ranked_docs)\n",
        "\n",
        "        doc_texts = [doc[0][1] for doc in ranked_docs]\n",
        "\n",
        "        query_embedding = self.sbert_model.encode(query)\n",
        "\n",
        "        doc_embeddings = self.sbert_model.encode(doc_texts)\n",
        "\n",
        "        # Calculating Cosine similarity\n",
        "        dot_product = np.dot(doc_embeddings, query_embedding)\n",
        "\n",
        "        doc_norms = np.linalg.norm(doc_embeddings, axis = 1)\n",
        "\n",
        "        query_norm = np.linalg.norm(query_embedding)\n",
        "\n",
        "        similarities = dot_product / (doc_norms * query_norm)\n",
        "\n",
        "        sorted_indices = np.argsort(similarities)[::-1]\n",
        "\n",
        "        reranked_docs = [(ranked_docs[i][0], similarities[i]) for i in sorted_indices[:top_k]]\n",
        "\n",
        "        for doc in reranked_docs:\n",
        "\n",
        "            print(f'\\nSemantic Score: {doc[1]:.4f}, Document {doc[0][0]}: \"{doc[0][1]}\"')\n",
        "\n",
        "        return reranked_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "MJXXK3s4ICwW"
      },
      "outputs": [],
      "source": [
        "documents = load_text_data(file_path)\n",
        "docs_df = pd.DataFrame(documents)\n",
        "\n",
        "text_data, vocabulary, dataframe = process_text(documents)\n",
        "\n",
        "BM25_model = BM25_Model(documents, text_data, vocabulary, dataframe)\n",
        "SBERT_model = SBERT_Model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daFo1Q29InAJ",
        "outputId": "291d88d0-3e57-408d-c7d6-ae28aa5a8662"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['deep', 'learning']\n",
            "\n",
            "Semantic Score: 0.3479, Document 236: \"neural network approach to ordinal regression ordinal regression is an important type of learning which ha property of both classification and regression here we describe simple and effective approach to adapt traditional neural network to learn ordinal category our approach is generalization of the perceptron method for ordinal regression on several benchmark datasets our method nnrank outperforms neural network classification method compared with the ordinal regression method using gaussian process and support vector machine nnrank achieves comparable performance moreover nnrank ha the advantage of traditional neural network learning in both online and batch mode handling very large training datasets and making rapid prediction these feature make nnrank useful and complementary tool for largescale data processing task such a information retrieval web page ranking collaborative filtering and protein ranking in bioinformatics\"\n",
            "\n",
            "Semantic Score: 0.3289, Document 160: \"learning from compressed observation the problem of statistical learning is to construct predictor of random variable a function of related random variable on the basis of an i.i.d training sample from the joint distribution of allowable predictor are drawn from some specified class and the goal is to approach asymptotically the performance expected loss of the best predictor in the class we consider the setting in which one ha perfect observation of the xpart of the sample while the ypart ha to be communicated at some finite bit rate the encoding of the yvalues is allowed to depend on the xvalues under suitable regularity condition on the admissible predictor the underlying family of probability distribution and the loss function we give an informationtheoretic characterization of achievable predictor performance in term of conditional distortionrate function the idea are illustrated on the example of nonparametric regression in gaussian noise\"\n",
            "\n",
            "Semantic Score: 0.2533, Document 5: \"parametric learning and monte carlo optimization this paper uncovers and explores the close relationship between monte carlo optimization of parametrized integral mco parametric machinelearning pl and blackbox or oraclebased optimization bo we make four contribution first we prove that mco is mathematically identical to broad class of pl problem this identity potentially provides new application domain for all broadly applicable pl technique mco second we introduce immediate sampling new version of the probability collective pc algorithm for blackbox optimization immediate sampling transforms the original bo problem into an mco problem accordingly by combining these first two contribution we can apply all pl technique to bo in our third contribution we validate this way of improving bo by demonstrating that crossvalidation and bagging improve immediate sampling finally conventional mc and mco procedure ignore the relationship between the sample point location and the associated value of the integrand only the value of the integrand at those location are considered we demonstrate that one can exploit the sample location information using pl technique for example by forming fit of the sample location to the associated value of the integrand this provides an additional way to apply pl technique to improve mco\"\n",
            "\n",
            "Semantic Score: 0.1504, Document 187: \"the vvds type agn sample the faint end of the luminosity function in previous paper gavignaud et al we presented the type active galactic nucleus agn sample obtained from the first epoch data of the vimosvlt deep survey vvds the sample consists of faint broadline agn with redshift up to and selected on the basis of their spectrum in this paper we present the measurement of the optical luminosity function up to z. derived from this sample we compare our result with previous result from brighter sample both at low and at high redshift our data more than one magnitude fainter than previous optical survey allow u to constrain the faint part of the luminosity function up to high redshift by combining our faint vvds sample with the large sample of bright agn extracted from the sdss dr richards et al. and testing number of different evolutionary model we find that the model which better represents the combined luminosity function over wide range of redshift and luminosity is luminosity dependent density evolution ldde model similar to those derived from the major xsurveys such parameterization allows the redshift of the agn space density peak to change a function of luminosity and explains the excess of faint agn that we find at .. on the basis of this model we find for the first time from the analysis of optically selected sample that the peak of the agn space density shift significantly towards lower redshift going to lower luminosity object this result already found in number of xray selected sample of agn is consistent with scenario of agn cosmic downsizing in which the density of more luminous agn possibly associated to more massive black hole peak earlier in the history of the universe than that of low luminosity one\"\n",
            "\n",
            "Semantic Score: 0.1463, Document 724: \"using conceptual metaphor and functional grammar to explore how language used in physic affect student learning this paper introduces theory about the role of language in learning physic the theory is developed in the context of physic student and physicist talking and writing about the subject of quantum mechanic we found that physicist language encodes different variety of analogical model through the use of grammar and conceptual metaphor we hypothesize that student categorize concept into ontological category based on the grammatical structure of physicist language we also hypothesize that student overextend and misapply conceptual metaphor in physicist speech and writing using our theory we will show how in some case we can explain student difficulty in quantum mechanic a difficulty with language\"\n",
            "\n",
            "Semantic Score: 0.1186, Document 520: \"blazar survey with wmap and swift we present the preliminary result from two new survey of blazars that have direct implication on the glast detection of extragalactic source from two different perspective microwave selection and combined deep xrayradio selection the first one is ghz fluxlimited sample extracted from the wmap yr catalog of microwave point source this is statistically well defined sample of about blazars and radio galaxy most of which are expected to be detected by glast the second one is new deep survey of blazars selected among the radio source that are spatially coincident with serendipitous source detected in deep xray image kev centered on the gamma ray burst grb discovered by the swift satellite this sample is particularly interesting from statistical viewpoint since it is unbiased a grbs explode at random position in the sky it is very deep in the xray band fx simgt erg with position accuracy of few arcsecond it will cover fairly large square deg area of sky it includes all blazars with radio flux ghz larger than mjy making it approximately two order of magnitude deeper than the wmap sample and about one order of magnitude deeper than the deepest existing complete sample of radio selected blazars and it can be used to estimate the amount of unresolved glast high latitude gammaray background and it anisotropy spectrum\"\n",
            "\n",
            "Semantic Score: 0.1139, Document 904: \"general system theory likequantum semantics and fuzzy set it is outlined the possibility to extend the quantum formalism in relation to the requirement of the general system theory it can be done by using quantum semantics arising from the deep logical structure of quantum theory it is so possible taking into account the logical openness relationship between observer and system we are going to show how considering the truthvalues of quantum proposition within the context of the fuzzy set is here more useful for systemics in conclusion we propose an example of formal quantum coherence\"\n",
            "\n",
            "Semantic Score: 0.1009, Document 686: \"the vimos vlt deep survey the assembly history of the stellar mass in galaxy from the young to the old universe we present detailed analysis of the galaxy stellar mass function of galaxy up to z. a obtained from the vvds we estimate the stellar mass from broadband photometry using different assumption on the galaxy star formation history and show that the addition of secondary burst to continuous star formation history produce systematically higher up to stellar mass at low redshift z. we find substantial population of lowmass galaxy msun composed by faint blue galaxy mimk .. in general the stellar mass function evolves slowly up to z. and more significantly above this redshift conversely massive tail is present up to z. and have extremely red colour mimk ... we find decline with redshift of the overall number density of galaxy for all mass for msun at and mild massdependent average evolution massdownsizing in particular our data are consistent with mildnegligible evolution up to z. for massive galaxy msun for less massive system the noevolution scenario is excluded large fraction of massive galaxy have been already assembled and converted most of their gas into star at ruling out the dry merger a the major mechanism of their assembly history below z. this fraction decrease to at z. lowmass system have decreased continuously in number and mass density by factor up to from the present age to consistently with prolonged mass assembly also at\"\n",
            "\n",
            "Semantic Score: 0.0927, Document 818: \"an optical source catalog of the north ecliptic pole region we present five band optical photometry catalog of the source in the north ecliptic pole nep region based on deep observation made with megacam at cfht the source catalog cover about square degree area centered at the nep and reach depth of about mag for band about mag for band and about mag for band sigma detection over an arcsec aperture the total number of cataloged source brighter than mag is about including both point source and extended source from the investigation of photometric property using the colormagnitude diagram and colorcolor diagram we have found that the color of extended source are mostly ur and gz .. this can be used to separate the extended source from the point source reliably even for the faint source domain where typical morphological classification scheme hardly work efficiently we have derived an empirical colorredshift relation of the red sequence galaxy using the sloan digital sky survey data by applying this relation to our photometry catalog and searching for any spatial overdensities we have found two galaxy cluster and one nearby galaxy group\"\n",
            "\n",
            "Semantic Score: 0.0874, Document 456: \"phononmediated decay of an atom in surfaceinduced potential we study phononmediated transition between translational level of an atom in surfaceinduced potential we present general master equation governing the dynamic of the translational state of the atom in the framework of the debye model we derive compact expression for the rate for both upward and downward transition numerical calculation for the transition rate are performed for deep silicainduced potential allowing for large number of bound level a well a free state of cesium atom the total absorption rate is shown to be determined mainly by the boundtobound transition for deep bound level and by boundtofree transition for shallow bound level moreover the phonon emission and absorption process can be order of magnitude larger for deep bound level a compared to the shallow bound one we also study various type of transition from free state we show that for thermal atomic cesium with temperature in the range from muk to muk in the vicinity of silica surface with temperature of the adsorption freetobound decay rate is about two time larger than the heating freetofree upward decay rate while the cooling freetofree downward decay rate is negligible\"\n",
            "\n",
            "Semantic Score: 0.0796, Document 789: \"ir observation of m star formation and it evolution in rich galaxy cluster we study the infrared ir property of galaxy in the cluster m at z. by combining mips micron data with spectrum of more than galaxy and very deep kband selected catalog ir cluster member are selected spectroscopically and an additional are selected by their photometric redshift we derive the ir luminosity function of the cluster and find strong evolution compared to the similarmass coma cluster the best fitting schechter function give lir .. lsun with fixed faint end slope about one order of magnitude larger than that in coma the rate of evolution of the ir luminosity from coma to m is consistent with that found in field galaxy and it suggests that some internal mechanism e.g. the consumption of the gas fuel is responsible for the general decline of the cosmic star formation rate sfr in different environment the massnormalized integrated sfr within .r in m also show evolution compared with other rich cluster at lower redshift but the trend is less conclusive if the mass selection effect is considered nonnegligible fraction of cluster member are forming star actively and the overdensity of ir galaxy is about compared to the field it is unlikely that cluster only passively accrete star forming galaxy from the surrounding field and have their star formation quenched quickly afterward instead many cluster galaxy still have large amount of gas and their star formation may be enhanced by the interaction with the cluster\"\n",
            "\n",
            "Semantic Score: 0.0702, Document 932: \"the haunted halo of andromeda and triangulum panorama of galaxy formation in action we present deep photometric survey of conducted with the cfht and int covering the inner kpc of the galaxy the southern quadrant out to kpc and extending to m. this is the first systematic panoramic study of this very outermost region of galaxy we detect several stream and other largescale structure and two new dwarf galaxy and xv and xvi the discovery of substructure on the minor axis together with the fact that the light profile between follows the exponential extended disk is particularly important in shedding light on the mixed and sometimes conflicting result reported in previous study underlying the substructure lie faint metalpoor smooth and extremely extended halo reaching out to at least kpc the smooth halo component in ha profile that can be fit with hernquist model of immense scale radius kpc almost factor of larger than theoretical prediction alternatively powerlaw with exponent can be fit to the profile the total luminosity of this structure is similar to that of the halo of the milky way this vast smooth underlying halo is reminiscent of classical monolithic model and completely unexpected from modern galaxy formation model is also found to have an extended metalpoor halo component which can be fit with hernquist model also of scale radius kpc these extended slowlydecreasing halo will provide challenge and strong constraint for further modeling abridged\"\n",
            "\n",
            "Semantic Score: 0.0526, Document 594: \"learning more from the lorentz transformation admitting the validity of lorentz transformation for the space a time coordinate of the same event we derive their differential form in order to underline the correct prerequisite for the application of time and length contraction or dilation effect furthermore we quantify the simultaneity error occurring in the relativity theory having done this we analyse the root cause of these effect and identify it with finite phase velocity associated with the moving frame we define this phase velocity by analogy to the de broglie wave associated with moving particle based on this construct we demonstrate that the phase of the de broglie wave further extended for stationary particle is relativistic invariant being the same for all corresponding observer also the phase of the electromagnetic wave transporting energy at light speed is relativistic invariant therefore the universe and it matter energy may be seen a superposition of wave propagating such that their phase is the same for all corresponding observer the wave phase may replace the time a an invariant and universal reference\"\n",
            "\n",
            "Semantic Score: 0.0450, Document 279: \"the radio emission xray emission and hydrodynamics of .. comprehensive analysis of luminous pulsar wind nebula it neutron star and the progenitor supernova explosion we present new observational result obtained for the galactic nonthermal radio source .. to determine both if this source is pulsar wind nebula or supernova remnant and in either case the physical property of this source using xray data obtained by xmm we confirm that the xray emission from this source is heavily absorbed and ha spectrum best fit by power law model of photon index with no evidence for thermal component the xray emission from .. come from region significantly smaller than the radio emission and that the xray and radio emission are significantly offset from each other we also present the result of new high resolution arcsecond ghz image of .. obtained using the australia telescope compact array and deep search for radio pulsation using the parkes radio telescope we find that the radio emission ha flat spectrum though some area along the eastern edge of .. have steeper radio spectral index of .. additionally we obtain luminosity limit of the central pulsar of mjy kpc assuming distance of kpc in light of these observational result we test if .. is pulsar wind nebula pwn or large pwn inside supernova remnant snr using simple hydrodynamic model for the evolution of pwn inside snr a result of this analysis we conclude that .. is young year old pulsar wind nebula formed by low magnetic field neutron star born spinning rapidly m expanding into an undetected snr formed by an energetic erg low ejecta mass solar mass supernova explosion which occurred in low density n. cm environment\"\n",
            "\n",
            "Semantic Score: 0.0428, Document 284: \"photometry of the sw sextype novalike bh lyncis in high state aim we present photometric study of the deeply eclipsing sw sextype novalike cataclysmic variable star bh lyn method timeresolved vband ccd photometry wa obtained for seven night between and result we determined new eclipse timing of bh lyn and derived refined orbital ephemeris with an orbital period of day during the observation bh lyn wa in highstate with v. mag the star present mag deep eclipse with mean fullwidth at halfflux of .. porb the eclipse shape is highly variable even changing form cycle to cycle this is most likely due to accretion disc surface brightness distribution variation most probably caused by strong flickering timedependent accretion disc selfoccultation or variation of the hot spot intensity are also possible explanation negative superhumps with period of day are detected in two long run in possible connection between sw sex and negative superhump phenomenon through the presence of tilted accretion disc is discussed and way to observationally test this is suggested\"\n",
            "\n",
            "Semantic Score: 0.0416, Document 943: \"strange nucleon form factor from ep and nu elastic scattering the recent parityviolating ep forwardscattering elastic asymmetry data from jefferson lab happex and when combined with the nu elastic cross section data from brookhaven permit an extraction of the strangeness contribution to the vector and axial nucleon form factor for momentum transfer in the range gev these result combined with the recent determination of the strange vector form factor at gev sample happex pva have been interpreted in term of uudsbars configuration very different from the kaonloop configuration usually associated with strangeness in the nucleon new experiment are being proposed to improve the state of our knowledge of the nu elastic cross section these new experiment will push the range of to much lower value and greatly increase the precision of the nu elastic data one outcome of this can be measurement of the strangeness contribution to the nucleon spin delta s. nuclear target e.g or ar are to be used in these neutrino experiment and so deep understanding of the nuclear physic particularly in regard to final state effect is needed before the potential of these precision experiment can be fully realized\"\n",
            "\n",
            "Semantic Score: 0.0334, Document 984: \"exploring first star era with glast cosmic infrared background cib includes emission from object inaccessible to current telescopic study such a the putative population iii the first star recently strong direct evidence for significant cib level produced by the first star came from cib fluctuation discovered in deep spitzer image such cib level should have left unique absorption feature in the spectrum of highz grbs and blazars a suggested in this is observable with glast source at and measuring this absorption will give important information on energetics and constituent of the first star era\"\n"
          ]
        }
      ],
      "source": [
        "query = \"deep learning\"\n",
        "processed_query = process_query(query, vocabulary)\n",
        "print(processed_query)\n",
        "\n",
        "ranked_docs = BM25_model.rank_documents(processed_query, TOP_N)\n",
        "ranked_docs = SBERT_model.rank_documents(ranked_docs, ' '.join(processed_query), TOP_K)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "voLj1uX_RFiC",
        "outputId": "81c8dd64-5abf-4264-a784-11d51a1a9796"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DocID</th>\n",
              "      <th>Title</th>\n",
              "      <th>Authors</th>\n",
              "      <th>Year</th>\n",
              "      <th>Score</th>\n",
              "      <th>Abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0704.1028</td>\n",
              "      <td>A neural network approach to ordinal regression</td>\n",
              "      <td>J, i, a, n, l, i, n,  , C, h, e, n, g</td>\n",
              "      <td>2007</td>\n",
              "      <td>0.3479</td>\n",
              "      <td>Ordinal regression is an important type of <b>learning</b> , which has properties of both classification and regression . Here we describe a simple an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0704.0671</td>\n",
              "      <td><b>Learning</b> from compressed observations</td>\n",
              "      <td>M, a, x, i, m,  , R, a, g, i, n, s, k, y</td>\n",
              "      <td>2016</td>\n",
              "      <td>0.3289</td>\n",
              "      <td>The problem of statistical <b>learning</b> is to construct a predictor of a random variable $ Y $ as a function of a related random variable $ X $ on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0704.1274</td>\n",
              "      <td>Parametric <b>Learning</b> and Monte Carlo Optimization</td>\n",
              "      <td>D, a, v, i, d,  , H, .,  , W, o, l, p, e, r, t,  , a, n, d,  , D, e, v,  , G, .,  , R, a, j, n, a, r, a, y, a, n</td>\n",
              "      <td>2011</td>\n",
              "      <td>0.2533</td>\n",
              "      <td>This paper uncovers and explores the close relationship between Monte Carlo Optimization of a parametrized integral ( MCO ) , Parametric machine-Learn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0704.1660</td>\n",
              "      <td>The VVDS type-1 AGN sample : The faint end of the luminosity function</td>\n",
              "      <td>A, .,  , B, o, n, g, i, o, r, n, o, ,,  , G, .,  , Z, a, m, o, r, a, n, i, ,,  , I, .,  , G, a, v, i, g, n, a, u, d, ,,  , B, .,  , M, a, r, a, n, o, ,,  , S, .,  , P, a, l, t, a, n, i, ,,  , G, ., \\n,  ,  , M, a, t, h, e, z, ,,  , J, ., P, .,  , P, i, c, a, t, ,,  , M, .,  , C, i, r, a, s, u, o, l, o, ,,  , F, .,  , L, a, m, a, r, e, i, l, l, e, ,,  , D, .,  , B, o, t, t, i, n, i, ,,  , B, .,  , G, a, r, i, l, l, i, ,,  , V, ., \\n,  ,  , L, e,  , B, r, u, n, ,,  , O, .,  , L, e,  , F, e, v, r, e, ,,  , D, .,  , M, a, c, c, a, g, n, i, ,,  , R, .,  , S, c, a, r, a, m, e, l, l, a, ,,  , M, .,  , S, c, o, d, e, g, g, i, o, ,,  , L, .,  , T, r, e, s, s, e, ,,  , G, ., \\n,  ,  , V, e, t, t, o, l, a, n, i, ,,  , A, .,  , Z, a, n, i, c, h, e, l, l, i, ,,  , C, .,  , A, d, a, m, i, ,,  , S, .,  , A, r, n, o, u, t, s, ,,  , S, .,  , B, a, r, d, e, l, l, i, ,,  , M, .,  , B, o, l, z, o, n, e, l, l, a, ,, \\n,  ,  , A, .,  , C, a, p, p, i, ,,  , S, .,  , C, h, a, r, l, o, t, ,,  , P, .,  , C, i, l, i, e, g, i, ,,  , T, .,  , C, o, n, t, i, n, i, ,,  , S, .,  , F, o, u, c, a, u, d, ,,  , P, .,  , F, r, a, n, z, e, t, t, i, ,,  , L, ., \\n,  ,  , G, u, z, z, o, ,,  , O, .,  , I, l, b, e, r, t, ,,  , A, .,  , I, o, v, i, n, o, ,,  , H, ., J, .,  , M, c, C, r, a, c, k, e, n, ,,  , C, .,  , M, a, r, i, n, o, n, ,,  , A, .,  , M, a, z, u, r, e, ,,  , B, ., \\n,  ,  , M, e, n, e, u, x, ,,  , R, .,  , M, e, r, i, g, h, i, ,,  , R, .,  , P, e, l, l, o, ', ,,  , A, .,  , P, o, l, l, o, ,,  , L, .,  , P, o, z, z, e, t, t, i, ,,  , M, .,  , R, a, d, o, v, i, c, h, ,,  , E, .,  , Z, u, c, c, a, ,, \\n,  ,  , E, .,  , H, a, t, z, i, m, i, n, a, o, g, l, o, u, ,,  , M, .,  , P, o, l, l, e, t, t, a, ,,  , M, .,  , B, o, n, d, i, ,,  , J, .,  , B, r, i, n, c, h, m, a, n, n, ,,  , O, .,  , C, u, c, c, i, a, t, i, ,,  , S, .,  , d, e, \\n,  ,  , l, a,  , T, o, r, r, e, ,,  , L, .,  , G, r, e, g, o, r, i, n, i, ,,  , Y, .,  , M, e, l, l, i, e, r, ,,  , P, .,  , M, e, r, l, u, z, z, i, ,,  , S, .,  , T, e, m, p, o, r, i, n, ,,  , D, .,  , V, e, r, g, a, n, i, ,, \\n,  ,  , C, ., J, .,  , W, a, l, c, h, e, r</td>\n",
              "      <td>2009</td>\n",
              "      <td>0.1504</td>\n",
              "      <td>In a previous paper ( Gavignaud et al . 2006 ) , we presented the type-1 Active Galactic Nuclei ( AGN ) sample obtained from the first epoch data of t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0704.1319</td>\n",
              "      <td>Using conceptual metaphor and functional grammar to explore how language used in physics affects student <b>learning</b></td>\n",
              "      <td>D, a, v, i, d,  , T, .,  , B, r, o, o, k, e, s, ,,  , E, u, g, e, n, i, a,  , E, t, k, i, n, a</td>\n",
              "      <td>2009</td>\n",
              "      <td>0.1463</td>\n",
              "      <td>This paper introduces a theory about the role of language in <b>learning</b> physics . The theory is developed in the context of physics students ' an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0704.1744</td>\n",
              "      <td>Blazar surveys with WMAP and Swift</td>\n",
              "      <td>P, .,  , G, i, o, m, m, i, ,,  , M, .,  , C, a, p, a, l, b, i, ,,  , E, .,  , C, a, v, a, z, z, u, t, i, ,,  , S, .,  , C, o, l, a, f, r, a, n, c, e, s, c, o, ,,  , S, .,  , C, u, t, i, n, i, ,,  , D, ., \\n,  ,  , G, a, s, p, a, r, r, i, n, i, ,,  , E, .,  , M, a, s, s, a, r, o, ,,  , P, .,  , P, a, d, o, v, a, n, i, ,,  , M, .,  , P, e, r, r, i, ,,  , S, .,  , P, u, c, c, e, t, t, i</td>\n",
              "      <td>2009</td>\n",
              "      <td>0.1186</td>\n",
              "      <td>We present the preliminary results from two new surveys of blazars that have direct implications on the GLAST detection of extragalactic sources from ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0704.0042</td>\n",
              "      <td>General System theory , Like-Quantum Semantics and Fuzzy Sets</td>\n",
              "      <td>I, g, n, a, z, i, o,  , L, i, c, a, t, a</td>\n",
              "      <td>2010</td>\n",
              "      <td>0.1139</td>\n",
              "      <td>It is outlined the possibility to extend the quantum formalism in relation to the requirements of the general systems theory . It can be done by using...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0704.1600</td>\n",
              "      <td>The VIMOS VLT <b>Deep</b> Survey . The Assembly History of the Stellar Mass in Galaxies : from the Young to the Old Universe</td>\n",
              "      <td>L, .,  , P, o, z, z, e, t, t, i, ,,  , M, .,  , B, o, l, z, o, n, e, l, l, a, ,,  , F, .,  , L, a, m, a, r, e, i, l, l, e, ,,  , G, .,  , Z, a, m, o, r, a, n, i, ,,  , P, .,  , F, r, a, n, z, e, t, t, i, ,, \\n,  ,  , O, .,  , L, e,  , F, \\, `, e, v, r, e, ,,  , A, .,  , I, o, v, i, n, o, ,,  , S, .,  , T, e, m, p, o, r, i, n, ,,  , O, .,  , I, l, b, e, r, t, ,,  , S, .,  , A, r, n, o, u, t, s, ,,  , S, .,  , C, h, a, r, l, o, t, ,,  , J, ., \\n,  ,  , B, r, i, n, c, h, m, a, n, n, ,,  , E, .,  , Z, u, c, c, a, ,,  , L, .,  , T, r, e, s, s, e, ,,  , M, .,  , S, c, o, d, e, g, g, i, o, ,,  , L, .,  , G, u, z, z, o, ,,  , D, .,  , B, o, t, t, i, n, i, ,,  , B, ., \\n,  ,  , G, a, r, i, l, l, i, ,,  , V, .,  , L, e,  , B, r, u, n, ,,  , D, .,  , M, a, c, c, a, g, n, i, ,,  , J, .,  , P, .,  , P, i, c, a, t, ,,  , R, .,  , S, c, a, r, a, m, e, l, l, a, ,,  , G, .,  , V, e, t, t, o, l, a, n, i, ,, \\n,  ,  , A, .,  , Z, a, n, i, c, h, e, l, l, i, ,,  , C, .,  , A, d, a, m, i, ,,  , S, .,  , B, a, r, d, e, l, l, i, ,,  , A, .,  , C, a, p, p, i, ,,  , P, .,  , C, i, l, i, e, g, i, ,,  , T, .,  , C, o, n, t, i, n, i, ,,  , S, ., \\n,  ,  , F, o, u, c, a, u, d, ,,  , I, .,  , G, a, v, i, g, n, a, u, d, ,,  , H, .,  , J, .,  , M, c, C, r, a, c, k, e, n, ,,  , B, .,  , M, a, r, a, n, o, ,,  , C, .,  , M, a, r, i, n, o, n, i, ,,  , A, .,  , M, a, z, u, r, e, ,,  , B, ., \\n,  ,  , M, e, n, e, u, x, ,,  , R, .,  , M, e, r, i, g, h, i, ,,  , S, .,  , P, a, l, t, a, n, i, ,,  , R, .,  , P, e, l, l, \\, `, o, ,,  , A, .,  , P, o, l, l, o, ,,  , M, .,  , R, a, d, o, v, i, c, h, ,,  , M, .,  , B, o, n, d, i, ,, \\n,  ,  , A, .,  , B, o, n, g, i, o, r, n, o, ,,  , O, .,  , C, u, c, c, i, a, t, i, ,,  , S, .,  , d, e,  , l, a,  , T, o, r, r, e, ,,  , L, .,  , G, r, e, g, o, r, i, n, i, ,,  , Y, .,  , M, e, l, l, i, e, r, ,,  , P, ., \\n,  ,  , M, e, r, l, u, z, z, i, ,,  , D, .,  , V, e, r, g, a, n, i, ,,  , C, .,  , J, .,  , W, a, l, c, h, e, r</td>\n",
              "      <td>2009</td>\n",
              "      <td>0.1009</td>\n",
              "      <td>We present a detailed analysis of the Galaxy Stellar Mass Function of galaxies up to z=2.5 as obtained from the VVDS . We estimate the stellar mass fr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0704.1182</td>\n",
              "      <td>An Optical Source Catalog of the North Ecliptic Pole Region</td>\n",
              "      <td>N, a, r, a, e,  , H, w, a, n, g,  , (, 1, ), ,,  , M, y, u, n, g,  , G, y, o, o, n,  , L, e, e,  , (, 1, ), ,,  , H, y, u, n, g,  , M, o, k,  , L, e, e,  , (, 1, ), ,,  , M, y, u, n, g, s, h, i, n,  , I, m, \\n,  ,  , (, 1, ), ,,  , T, a, e, h, y, u, n,  , K, i, m,  , (, 1, ), ,,  , H, i, d, e, o,  , M, a, t, s, u, h, a, r, a,  , (, 2, ), ,,  , T, a, k, e, h, i, k, o,  , W, a, d, a,  , (, 2, ), ,,  , S, h, i, n, k, i,  , O, y, a, b, u, \\n,  ,  , (, 2, ), ,,  , S, o, o, j, o, n, g,  , P, a, k,  , (, 3, ), ,,  , M, o, o, -, Y, o, u, n, g,  , C, h, u, n,  , (, 4, ), ,,  , H, i, d, e, n, o, r, i,  , W, a, t, a, r, a, i,  , (, 5, ), ,,  , T, a, k, a, o, \\n,  ,  , N, a, k, a, g, a, w, a,  , (, 4, ), ,,  , C, h, r, i, s,  , P, e, a, r, s, o, n,  , (, 2, ,, 6, ), ,,  , T, o, s, h, i, n, o, b, u,  , T, a, k, a, g, i,  , (, 2, ), ,,  , H, i, t, o, s, h, i,  , H, a, n, a, m, i,  , (, 7, ), ,, \\n,  ,  , G, l, e, n, n,  , J, .,  , W, h, i, t, e,  , (, 8, ,, 9, ),  , (, (, 1, ),  , S, N, U,  , K, o, r, e, a, ,,  , (, 2, ),  , I, S, A, S,  , J, A, X, A,  , J, a, p, a, n, ,,  , (, 3, ), K, H, U,  , K, o, r, e, a, ,, \\n,  ,  , (, 4, ), K, A, S, I,  , K, o, r, e, a, ,,  , (, 5, ),  , O, S, A,  , J, A, X, A,  , J, a, p, a, n, ,,  , (, 6, ),  , E, S, A,  , S, p, a, i, n, ,,  , (, 7, ),  , I, w, a, t, e,  , U, n, i, v, .,  , J, a, p, a, n, ,,  , (, 8, ), \\n,  ,  , O, p, e, n,  , U, n, i, v, .,  , U, K, ,,  , (, 9, ),  , C, C, L, R, C,  , R, A, L,  , U, K, )</td>\n",
              "      <td>2009</td>\n",
              "      <td>0.0927</td>\n",
              "      <td>We present a five ( u * , g ' , r ' , i ' , z ' ) band optical photometry catalog of the sources in the North Ecliptic Pole ( NEP ) region based on <b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0704.0340</td>\n",
              "      <td>Phonon-mediated decay of an atom in a surface-induced potential</td>\n",
              "      <td>F, a, m,  , L, e,  , K, i, e, n, ,,  , S, .,  , D, u, t, t, a,  , G, u, p, t, a, ,,  , a, n, d,  , K, .,  , H, a, k, u, t, a</td>\n",
              "      <td>2007</td>\n",
              "      <td>0.0874</td>\n",
              "      <td>We study phonon-mediated transitions between translational levels of an atom in a surface-induced potential . We present a general master equation gov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0704.0953</td>\n",
              "      <td>IR observations of MS 1054-03 : Star Formation and its Evolution in Rich Galaxy Clusters</td>\n",
              "      <td>L, e, i,  , B, a, i, ,,  , D, e, l, p, h, i, n, e,  , M, a, r, c, i, l, l, a, c, ,,  , G, e, o, r, g, e,  , H, .,  , R, i, e, k, e, ,,  , M, a, r, c, i, a,  , J, .,  , R, i, e, k, e, ,,  , K, i, m, -, V, y, \\n,  ,  , H, .,  , T, r, a, n, ,,  , J, o, a, n, n, a, h,  , L, .,  , H, i, n, z, ,,  , G, r, e, g, o, r, y,  , R, u, d, n, i, c, k, ,,  , D, o, u, g, l, a, s,  , M, .,  , K, e, l, l, y, ,,  , M, y, r, a,  , B, l, a, y, l, o, c, k</td>\n",
              "      <td>2009</td>\n",
              "      <td>0.0796</td>\n",
              "      <td>We study the infrared ( IR ) properties of galaxies in the cluster MS 1054-03 at z=0.83 by combining MIPS 24 micron data with spectra of more than 400...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0704.1318</td>\n",
              "      <td>The Haunted Halos of Andromeda and Triangulum : A panorama of galaxy formation in action</td>\n",
              "      <td>R, .,  , I, b, a, t, a, ,,  , N, .,  , F, .,  , M, a, r, t, i, n, ,,  , M, .,  , I, r, w, i, n, ,,  , S, .,  , C, h, a, p, m, a, n, ,,  , A, .,  , M, .,  , N, .,  , F, e, r, g, u, s, o, n, ,,  , G, .,  , F, ., \\n,  ,  , L, e, w, i, s, ,,  , A, .,  , W, .,  , M, c, C, o, n, n, a, c, h, i, e</td>\n",
              "      <td>2009</td>\n",
              "      <td>0.0702</td>\n",
              "      <td>We present a <b>deep</b> photometric survey of M31 , conducted with the CFHT and INT , covering the inner 50 kpc of the galaxy , the Southern quadrant...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0704.1786</td>\n",
              "      <td><b>Learning</b> more from the Lorentz transformations</td>\n",
              "      <td>S, t, e, f, a, n,  , P, o, p, e, s, c, u,  , a, n, d,  , B, e, r, n, h, a, r, d,  , R, o, t, h, e, n, s, t, e, i, n</td>\n",
              "      <td>2008</td>\n",
              "      <td>0.0526</td>\n",
              "      <td>Admitting the validity of Lorentz transformations for the space as time coordinates of the same event we derive their differential form in order to un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0704.0219</td>\n",
              "      <td>The Radio Emission , X-ray Emission , and Hydrodynamics of G328.4+0.2 : A Comprehensive Analysis of a Luminous Pulsar Wind Nebula , its Neutron Star , and the Progenitor Supernova Explosion</td>\n",
              "      <td>J, o, s, e, p, h,  , D, .,  , G, e, l, f, a, n, d, ,,  , B, .,  , M, .,  , G, a, e, n, s, l, e, r, ,,  , P, a, t, r, i, c, k,  , O, .,  , S, l, a, n, e, ,,  , D, a, n, i, e, l,  , J, ., \\n,  ,  , P, a, t, n, a, u, d, e, ,,  , J, o, h, n,  , P, .,  , H, u, g, h, e, s, ,,  , F, e, r, n, a, n, d, o,  , C, a, m, i, l, o</td>\n",
              "      <td>2009</td>\n",
              "      <td>0.0450</td>\n",
              "      <td>We present new observational results obtained for the Galactic non-thermal radio source G328.4+0.2 to determine both if this source is a pulsar wind n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0704.1302</td>\n",
              "      <td>Photometry of the SW Sex-type nova-like BH Lyncis in high state</td>\n",
              "      <td>V, .,  , S, t, a, n, i, s, h, e, v, ,,  , Z, .,  , K, r, a, i, c, h, e, v, a, ,,  , V, .,  , G, e, n, k, o, v</td>\n",
              "      <td>2007</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>Aims : We present a photometric study of the deeply eclipsing SW Sex-type nova-like cataclysmic variable star BH Lyn Methods : Time-resolved V-band CC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0704.1115</td>\n",
              "      <td>Strange Nucleon Form Factors from $ ep $ and $ \\nu p $ Elastic Scattering</td>\n",
              "      <td>S, t, e, p, h, e, n,  , P, a, t, e</td>\n",
              "      <td>2008</td>\n",
              "      <td>0.0416</td>\n",
              "      <td>The recent parity-violating $ ep $ forward-scattering elastic asymmetry data from Jefferson Lab ( HAPPEx and G0 ) , when combined with the $ \\nu p $ e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0704.0225</td>\n",
              "      <td>Exploring First Stars Era with GLAST</td>\n",
              "      <td>A, .,  , K, a, s, h, l, i, n, s, k, y,  , a, n, d,  , D, .,  , B, a, n, d</td>\n",
              "      <td>2009</td>\n",
              "      <td>0.0334</td>\n",
              "      <td>Cosmic infrared background ( CIB ) includes emissions from objects inaccessible to current telescopic studies , such as the putative Population III , ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ground_truth = [236, 160, 5, 904, 187]\n",
        "predicted_labels = [doc[0][0] for doc in ranked_docs]\n",
        "scores = [doc[1] for doc in ranked_docs]\n",
        "\n",
        "results_df = display_results(predicted_labels, scores, docs_df, processed_query)\n",
        "display(HTML(results_df.to_html(escape = False)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "rSXU-TWVOcrN"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(true_labels, pred_labels):\n",
        "\n",
        "  tp, fp = 0, 0\n",
        "  fn = 0\n",
        "\n",
        "  for pred in pred_labels:\n",
        "\n",
        "    if pred in true_labels:\n",
        "\n",
        "      tp += 1\n",
        "    else:\n",
        "      fp += 1\n",
        "\n",
        "  for true in true_labels:\n",
        "    if true not in pred_labels:\n",
        "      fn += 1\n",
        "\n",
        "  precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "  recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "  f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "  return precision, recall, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "jTMQOVnoPTJy"
      },
      "outputs": [],
      "source": [
        "def ndcg_at_k(retrieved, relevant, k):\n",
        "    \"\"\"Compute nDCG at k. Here binary relevance (1 if relevant, 0 if not).\"\"\"\n",
        "    dcg = 0.0\n",
        "\n",
        "    for i, doc_id in enumerate(retrieved[:k], start=1):\n",
        "\n",
        "        rel = 1 if doc_id in relevant else 0\n",
        "\n",
        "        dcg += (2**rel - 1) / math.log2(i + 1)\n",
        "    # Compute ideal DCG\n",
        "    ideal_rel = [1] * min(len(relevant), k)\n",
        "\n",
        "    idcg = sum((2**rel - 1) / math.log2(i + 1) for i, rel in enumerate(ideal_rel, start=1))\n",
        "\n",
        "    if idcg == 0:\n",
        "\n",
        "        return 0.0\n",
        "\n",
        "    return dcg / idcg\n",
        "\n",
        "def reciprocal_rank(retrieved, relevant):\n",
        "    \"\"\"Compute the reciprocal rank for a single query.\"\"\"\n",
        "    for i, doc_id in enumerate(retrieved, start  = 1):\n",
        "\n",
        "        if doc_id in relevant:\n",
        "\n",
        "            return 1.0 / i\n",
        "\n",
        "    return 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI7SL8IUK5-I",
        "outputId": "209f8bf6-24a7-4a7e-f171-e98b93d9b75d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.29411764705882354\n",
            "Recall: 1.0\n",
            "F1-score: 0.45454545454545453\n",
            "Ndcg: 0.9818483242455303\n",
            "Reciprocal Rank: 1.0\n"
          ]
        }
      ],
      "source": [
        "precision, recall, f1_score = compute_metrics(ground_truth, predicted_labels)\n",
        "ndcg = ndcg_at_k(predicted_labels, ground_truth, TOP_K)\n",
        "reciprocal_rank = reciprocal_rank(predicted_labels, ground_truth)\n",
        "\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1-score: {f1_score}')\n",
        "\n",
        "print(f'nDCG: {ndcg}')\n",
        "print(f'Reciprocal Rank: {reciprocal_rank}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
